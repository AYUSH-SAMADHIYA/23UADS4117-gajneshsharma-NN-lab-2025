{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron(inputs, weights, bias):\n",
    "    return np.where(np.dot(inputs, weights) + bias > 0, 1, 0)\n",
    "\n",
    "def xor_mlp(x):\n",
    "    # Define weights and biases for the hidden layer perceptrons\n",
    "    p1_w = np.array([1, -1])  # AND-like perceptron\n",
    "    p2_w = np.array([-1, 1])  # AND-like perceptron\n",
    "    p3_w = np.array([1, 1])   # OR perceptron\n",
    "    p4_w = np.array([-1, -1]) # NOR perceptron\n",
    "    \n",
    "    p1_b = 0\n",
    "    p2_b = 0\n",
    "    p3_b = -0.5\n",
    "    p4_b = 0.5\n",
    "    \n",
    "    # Compute hidden layer outputs\n",
    "    h1 = perceptron(x, p1_w, p1_b)\n",
    "    h2 = perceptron(x, p2_w, p2_b)\n",
    "    h3 = perceptron(x, p3_w, p3_b)\n",
    "    h4 = perceptron(x, p4_w, p4_b)\n",
    "    \n",
    "    # Combine hidden layer outputs into an array\n",
    "    hidden_output = np.stack((h1, h2, h3, h4), axis=1)\n",
    "    \n",
    "    # XOR perceptron (using h1 and h2, ignoring h3 and h4)\n",
    "    xor_w = np.array([1, 1, 0, 0])\n",
    "    xor_b = 0\n",
    "    \n",
    "    # Compute final XOR output\n",
    "    return perceptron(hidden_output, xor_w, xor_b)\n",
    "\n",
    "# XOR truth table inputs\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = xor_mlp(X)\n",
    "\n",
    "# Print results\n",
    "for i in range(len(X)):\n",
    "    print(f'Input: {X[i]} -> XOR Output: {Y[i]}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
